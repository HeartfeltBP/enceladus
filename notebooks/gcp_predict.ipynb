{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os, shutil\n",
    "import numpy as np\n",
    "import keras\n",
    "from google.cloud import aiplatform\n",
    "from enceladus.jobs import TestingPipeline\n",
    "import wandb\n",
    "\n",
    "# tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-11 21:29:13.937389: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-11 21:29:13.984924: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-11 21:29:13.985182: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-11 21:29:13.985979: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-11 21:29:13.986478: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-11 21:29:13.986711: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-11 21:29:13.986925: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-11 21:29:14.673487: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-11 21:29:14.673744: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-11 21:29:14.673960: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-11 21:29:14.674464: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5508 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('/home/cam/Documents/enceladus/notebooks/artifacts/model-vital-bee-206:v19/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 40). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/cam/Documents/enceladus/vital-bee-206-serving/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/cam/Documents/enceladus/vital-bee-206-serving/assets\n"
     ]
    }
   ],
   "source": [
    "@tf.function()\n",
    "def heartfelt_predict(ppg, vpg, apg):\n",
    "   inputs = {\n",
    "        'ppg': ppg,\n",
    "        'vpg': vpg,\n",
    "        'apg': apg,\n",
    "   }\n",
    "   prediction = model(inputs)\n",
    "   return {'abp': prediction}\n",
    "\n",
    "signatures = heartfelt_predict.get_concrete_function(\n",
    "   ppg=tf.TensorSpec([None, 256, 1], dtype=tf.dtypes.float32, name='ppg'),\n",
    "   vpg=tf.TensorSpec([None, 256, 1], dtype=tf.dtypes.float32, name='vpg'),\n",
    "   apg=tf.TensorSpec([None, 256, 1], dtype=tf.dtypes.float32, name='apg'),\n",
    ")\n",
    "\n",
    "tf.saved_model.save(\n",
    "    model,\n",
    "    export_dir='/home/cam/Documents/enceladus/vital-bee-206-serving/',\n",
    "    signatures=signatures,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.ones((1, 256))\n",
    "model.predict([x, x, x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.saved_model.load(\n",
    "    export_dir='/home/cam/Documents/enceladus/notebooks/artifacts/model-vital-bee-206:v19/',\n",
    "    tags=[tf.saved_model.SERVING],\n",
    ")\n",
    "\n",
    "p = tf.compat.v1.placeholder(tf.float64, [None, 256], 'ppg')\n",
    "v = tf.compat.v1.placeholder(tf.float64, [None, 256], 'vpg')\n",
    "a = tf.compat.v1.placeholder(tf.float64, [None, 256], 'apg')\n",
    "y = tf.compat.v1.placeholder(tf.float64, [None, 256], 'abp')\n",
    "\n",
    "sess = tf.compat.v1.Session()\n",
    "sess.run(tf.compat.v1.global_variables_initializer())\n",
    "\n",
    "ppg_input = tf.compat.v1.saved_model.utils.build_tensor_info(p)\n",
    "vpg_input = tf.compat.v1.saved_model.utils.build_tensor_info(v)\n",
    "apg_input = tf.compat.v1.saved_model.utils.build_tensor_info(a)\n",
    "info_output = tf.compat.v1.saved_model.utils.build_tensor_info(y)\n",
    "\n",
    "signature = tf.compat.v1.saved_model.signature_def_utils.build_signature_def(\n",
    "        inputs={'ppg': ppg_input, 'vpg': vpg_input, 'apg': apg_input},\n",
    "        outputs={'abp': info_output},\n",
    "        method_name=tf.saved_model.PREDICT_METHOD_NAME\n",
    ")\n",
    "\n",
    "saver.add_meta_graph_and_variables(\n",
    "        sess,\n",
    "        [tf.saved_model.SERVING],\n",
    "        signature_def_map={'predict': signature},\n",
    ")\n",
    "saver.save()\n",
    "\n",
    "# Close and clean up\n",
    "sess.close()\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input (2D)\n",
    "x = np.array([[x1,x2] for x1 in np.linspace(10,20,4) for x2 in np.linspace(-7,-3,3)])\n",
    "\n",
    "# Output (3D)\n",
    "f = np.array([[np.sin(np.sum(xx)),np.cos(np.sum(xx)),np.cos(np.sum(xx))**2] for xx in x])\n",
    "\n",
    "#%% Model\n",
    "\n",
    "print('**********************************************')\n",
    "print('TF - save')\n",
    "\n",
    "# Dimension of input x and output f\n",
    "d_x = x.shape[-1]\n",
    "d_f = f.shape[-1]\n",
    "\n",
    "# Placeholders\n",
    "x_p = tf.placeholder(tf.float64,[None,d_x],'my_x_p')\n",
    "f_p = tf.placeholder(tf.float64,[None,d_f],'my_f_p')\n",
    "\n",
    "# Model\n",
    "model = x_p\n",
    "model = tf.layers.dense(model,7,tf.tanh)\n",
    "model = tf.layers.dense(model,5,tf.tanh)\n",
    "model = tf.layers.dense(model,d_f,None)\n",
    "model = tf.identity(model,'my_model')\n",
    "\n",
    "# Session\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Evaluate for later check of serving\n",
    "f_model = sess.run(model,{x_p:x})\n",
    "folder = 'data'\n",
    "if not os.path.exists(folder):\n",
    "    os.mkdir(folder)\n",
    "np.savetxt('data/x.dat',f_model)\n",
    "np.savetxt('data/f_model.dat',f_model)\n",
    "\n",
    "# Save model\n",
    "folder = 'saved/model/001'\n",
    "if os.path.exists(folder):\n",
    "    shutil.rmtree(folder)\n",
    "    print('Old model deleted')\n",
    "saver = tf.saved_model.builder.SavedModelBuilder(folder)\n",
    "############################################\n",
    "# HOW DO I SET UP THE SIGNATURE CORRECTLY?\n",
    "############################################\n",
    "info_input = tf.saved_model.utils.build_tensor_info(x_p)\n",
    "info_output = tf.saved_model.utils.build_tensor_info(model)\n",
    "signature = tf.saved_model.signature_def_utils.build_signature_def(\n",
    "        inputs={'x':info_input}\n",
    "        ,outputs={'f':info_output}\n",
    "        ,method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME\n",
    "        )\n",
    "saver.add_meta_graph_and_variables(\n",
    "        sess\n",
    "        ,[tf.saved_model.tag_constants.SERVING]\n",
    "        ,signature_def_map={'predict':signature}\n",
    "        ####################################################################\n",
    "        ### WHAT DO I NEED TO PUT HERE IN ORDER TO CALL THE MODEL LATER ON \n",
    "        ### WHILE SERVING WITH DOCKER AND HOW DO I CALL IT IN DOCKER??\n",
    "        ####################################################################\n",
    "        )\n",
    "saver.save()\n",
    "\n",
    "# Close and clean up\n",
    "sess.close()\n",
    "tf.reset_default_graph()\n",
    "\n",
    "#%% Load in Python and check\n",
    "\n",
    "print('**********************************************')\n",
    "print('TF - load in Python')\n",
    "\n",
    "# Session\n",
    "sess = tf.Session()\n",
    "\n",
    "# Load\n",
    "tf.saved_model.loader.load(\n",
    "        sess\n",
    "        ,[tf.saved_model.tag_constants.SERVING]\n",
    "        ,folder\n",
    "        )\n",
    "\n",
    "# Extract operations from graph\n",
    "graph = tf.get_default_graph()\n",
    "x_p = graph.get_tensor_by_name('my_x_p:0')\n",
    "f_p = graph.get_tensor_by_name('my_f_p:0')\n",
    "model = graph.get_tensor_by_name('my_model:0')\n",
    "\n",
    "# Evaluate model\n",
    "f_model2 = sess.run(model,{x_p:x})\n",
    "print(f_model - f_model2)\n",
    "\n",
    "# Close and clean up\n",
    "sess.close()\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppg, vpg, apg, abp = TestingPipeline(\n",
    "    data_path='/home/cam/Documents/database_tools/data/data-2022-11-08/mimic3/',\n",
    "    scaler_path='/home/cam/Documents/database_tools/data/data-2022-11-08/mimic3/scalers_MinMax.pkl',\n",
    "    scaler_type='MinMax',\n",
    "    model_path='heartfelt/Enceladus/model-vital-bee-206:v19',\n",
    ").run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_CLOUD_PROJECT = 'heartfelt-0'\n",
    "GOOGLE_CLOUD_REGION = 'us-central1'\n",
    "ENDPOINT_ID = 4207052545266286592\n",
    "\n",
    "# The AI Platform services require regional API endpoints.\n",
    "client_options = {\n",
    "    'api_endpoint': GOOGLE_CLOUD_REGION + '-aiplatform.googleapis.com'\n",
    "    }\n",
    "# Initialize client that will be used to create and send requests.\n",
    "client = aiplatform.gapic.PredictionServiceClient(client_options=client_options)\n",
    "\n",
    "# Set data values for the prediction request.\n",
    "# Our model expects 4 feature inputs and produces 3 output values for each\n",
    "# species. Note that the output is logit value rather than probabilities.\n",
    "# See the model code to understand input / output structure.\n",
    "instances = [{\n",
    "    'ppg': [1] * 256,\n",
    "    'vpg': [1] * 256,\n",
    "    'apg': [1] * 256,\n",
    "}]\n",
    "\n",
    "endpoint = client.endpoint_path(\n",
    "    project=GOOGLE_CLOUD_PROJECT,\n",
    "    location=GOOGLE_CLOUD_REGION,\n",
    "    endpoint=ENDPOINT_ID,\n",
    ")\n",
    "# Send a prediction request and get response.\n",
    "response = client.predict(endpoint=endpoint, instances=instances)\n",
    "\n",
    "response.predictions[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enceladus-w-_QEyfy-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "32db32f0218b6b96da4712f2a68dfad516c8744583a5e43ba77c08ec53bc2944"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
